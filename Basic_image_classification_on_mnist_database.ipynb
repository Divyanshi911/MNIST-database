{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic image classification on mnist database.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import keras"
      ],
      "metadata": {
        "id": "nas09dn62gB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist(flatten=False):\n",
        "    (X_train,Y_train),(X_test,Y_test)=keras.datasets.mnist.load_data()\n",
        "    print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n",
        "    #normalizations\n",
        "    X_train=X_train.astype(float)/255\n",
        "    X_test=X_test.astype(float)/255\n",
        "    \n",
        "    #data separation\n",
        "    X_train=X_train[:-10000]\n",
        "    X_val=X_train[-10000:]\n",
        "    Y_train=Y_train[:-10000]\n",
        "    Y_val=Y_train[-10000:]\n",
        "    \n",
        "    print(X_val.shape,Y_val.shape)\n",
        "    \n",
        "    if flatten:\n",
        "        X_train=X_train.reshape([X_train.shape[0],-1])\n",
        "        X_val=X_val.reshape([X_val.shape[0],-1])\n",
        "        X_train=X_train.reshape([X_test.shape[0],-1])\n",
        "    return X_train,Y_train,X_val,Y_val,X_test,Y_test\n",
        "    "
      ],
      "metadata": {
        "id": "tzdyZ_9L2k3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,Y_train,X_val,Y_val,X_test,Y_test=load_mnist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP3AWGgL2oMK",
        "outputId": "eedb0b6c-8ce2-42af-ac7d-dc92567808f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train[0])\n",
        "plt.imshow(X_train[0],cmap='Greys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "A8HB4zkx2oNB",
        "outputId": "49e3ba2c-42c5-4a1a-d0fe-1b5331933c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8db9e11b50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owEobusL2oRR",
        "outputId": "261f8f03-1fb5-4eb3-c101-9c84ae590ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxjwI7I-2oR7",
        "outputId": "d86ae0d6-71d1-4b48-d0c7-7b72832bc816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Changing dimensions of input from N*28*28 TO N*784**"
      ],
      "metadata": {
        "id": "T4Y_7FEy3bOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqnR6KiL4PtK",
        "outputId": "d846fa84-72d4-4704-87ef-1fa3f326c2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.reshape((X_train.shape[0],\n",
        "                        X_train.shape[1]* X_train.shape[2]))\n",
        "X_test=X_test.reshape((X_test.shape[0],\n",
        "                      X_test.shape[1]*X_test.shape[2]))"
      ],
      "metadata": {
        "id": "Bs9iTzhQ5AQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5rQb3AV5MIP",
        "outputId": "9223dac7-4e17-4e73-cc2e-709fd58dc32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train=LabelBinarizer().fit_transform(Y_train)\n",
        "Y_test=LabelBinarizer().fit_transform(Y_test)"
      ],
      "metadata": {
        "id": "WibBJs5w53i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFGKr5up64Sj",
        "outputId": "0399e281-20b1-4468-fe9e-b79027b08f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=Y_train.shape[1]\n",
        "num_features=X_train.shape[1]\n",
        "num_output=Y_train.shape[1]\n",
        "num_layers_0=512\n",
        "num_layers_1=256\n",
        "start_learning_rate=0.001\n",
        "regularizer_rate=0.1"
      ],
      "metadata": {
        "id": "21We90dL53jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sch8g6y553v8",
        "outputId": "711b9f00-6d94-4888-bcfd-36ec07de92e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_X=tf.placeholder('float32',\n",
        "                       shape=(None, num_features),\n",
        "                      name=\"input_X\")\n",
        "input_Y=tf.placeholder('float32',\n",
        "                       shape=(None, num_classes),\n",
        "                      name=\"input_Y\")\n",
        "keep_prob=tf.placeholder(tf.float32)"
      ],
      "metadata": {
        "id": "i_sV8djH53wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input layer\n",
        "weight_0=tf.Variable(tf.random_normal([num_features,\n",
        "                num_layers_0],\n",
        "        stddev=1/tf.sqrt(float(num_features))))\n",
        "bias_0=tf.Variable(tf.random_normal([num_layers_0]))\n",
        "\n",
        "weight_1=tf.Variable(tf.random_normal([num_layers_0,\n",
        "                num_layers_1],\n",
        "        stddev=1/tf.sqrt(float(num_layers_0))))\n",
        "bias_1=tf.Variable(tf.random_normal([num_layers_1]))\n",
        "\n",
        "\n",
        "#output layer\n",
        "weight_2=tf.Variable(tf.random_normal([num_layers_1,\n",
        "                num_output],\n",
        "        stddev=1/tf.sqrt(float(num_layers_1))))\n",
        "bias_2=tf.Variable(tf.random_normal([num_output]))"
      ],
      "metadata": {
        "id": "2Gdr2j0O532F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_output_0=tf.nn.relu(tf.matmul(input_X,\n",
        "                                     weight_0)+bias_0)\n",
        "\n",
        "hidden_output_0_0=tf.nn.dropout(hidden_output_0,\n",
        "                                keep_prob)\n",
        "\n",
        "hidden_output_1=tf.nn.relu(tf.matmul(hidden_output_0_0,\n",
        "                                     weight_1)+bias_1)\n",
        "hidden_output_1_1=tf.nn.dropout(hidden_output_1,\n",
        "                                keep_prob)\n",
        "\n",
        "predicted_y=tf.sigmoid(tf.matmul(hidden_output_1_1,\n",
        "                                weight_2)+bias_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keZZNSGvBc5c",
        "outputId": "c899230e-ef20-40f9-a72b-b3da940facf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predicted_y,labels=input_Y))+regularizer_rate*(tf.reduce_mean(tf.square(bias_0)) *tf.reduce_mean(tf.square(bias_1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ-EmpyODt9Y",
        "outputId": "d1c0cc57-6e4b-4cc9-a6d2-ff2673f18b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=tf.train.exponential_decay(start_learning_rate,\n",
        "      0, 5, 0.85, staircase=True)\n",
        "optimizer=tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
        "            var_list=[weight_0, weight_1, weight_2,\n",
        "                    bias_0, bias_1, bias_2])"
      ],
      "metadata": {
        "id": "sJy1qdIKDt-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_prediction=tf.equal(tf.argmax(Y_train,1),\n",
        "tf.argmax(predicted_y,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_prediction,\n",
        "                                tf.float32))"
      ],
      "metadata": {
        "id": "s7ZpWHUlDuBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=128\n",
        "epochs=125\n",
        "dropout_prob=0.6"
      ],
      "metadata": {
        "id": "3_aAYilAILbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_accuracy=[]\n",
        "training_loss=[]\n",
        "testing_accuracy=[]"
      ],
      "metadata": {
        "id": "ZAil4MYPDuHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s=tf.InteractiveSession()"
      ],
      "metadata": {
        "id": "GTQX1fQ0IluW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "7Cz1JvV5Ir4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.run(tf.global_variables_initializer())\n",
        "for epoch in range(epochs):\n",
        "    arr=np.arange(X_train.shape[0])\n",
        "    np.random.shuffle(arr)\n",
        "    for index in range(0, X_train.shape[0], batch_size):\n",
        "        s.run(optimizer,{input_X:X_train[arr[index:index+batch_size]],\n",
        "                         input_Y:Y_train[arr[index:index+batch_size]],keep_prob:dropout_prob})\n",
        "        \n",
        "    training_accuracy.append(s.run(accuracy,\n",
        "            feed_dict={input_X:X_train,\n",
        "                      input_Y:Y_train, keep_prob:1}))\n",
        "    testing_accuracy.append(accuracy_score(Y_test.argmax(1),\n",
        "                s.run(predicted_y,{input_X:X_test, keep_prob:1}).argmax(1)))\n",
        "        \n",
        "    training_loss.append(s.run(loss,\n",
        "                        {input_X: X_train,\n",
        "                        input_Y: Y_train, keep_prob:1}))\n",
        "        \n",
        "    print(\"Epochs:{0}, Train loss:{1:.2f}, Train accu: {2:.3f},Test accu:{3:.3f}\".format(epoch,\n",
        "                training_loss[epoch], training_accuracy[epoch],testing_accuracy[epoch]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdEomV9JIr5O",
        "outputId": "68e97a09-456f-4701-ff8b-03f492024eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs:0, Train loss:1.56, Train accu: 0.936,Test accu:0.936\n",
            "Epochs:1, Train loss:1.52, Train accu: 0.955,Test accu:0.954\n",
            "Epochs:2, Train loss:1.50, Train accu: 0.967,Test accu:0.964\n",
            "Epochs:3, Train loss:1.49, Train accu: 0.971,Test accu:0.966\n",
            "Epochs:4, Train loss:1.48, Train accu: 0.976,Test accu:0.970\n",
            "Epochs:5, Train loss:1.48, Train accu: 0.980,Test accu:0.973\n",
            "Epochs:6, Train loss:1.48, Train accu: 0.983,Test accu:0.975\n",
            "Epochs:7, Train loss:1.48, Train accu: 0.984,Test accu:0.975\n",
            "Epochs:8, Train loss:1.47, Train accu: 0.985,Test accu:0.974\n",
            "Epochs:9, Train loss:1.47, Train accu: 0.987,Test accu:0.978\n",
            "Epochs:10, Train loss:1.47, Train accu: 0.988,Test accu:0.979\n",
            "Epochs:11, Train loss:1.47, Train accu: 0.988,Test accu:0.979\n",
            "Epochs:12, Train loss:1.47, Train accu: 0.989,Test accu:0.979\n",
            "Epochs:13, Train loss:1.47, Train accu: 0.990,Test accu:0.978\n",
            "Epochs:14, Train loss:1.47, Train accu: 0.991,Test accu:0.979\n",
            "Epochs:15, Train loss:1.47, Train accu: 0.991,Test accu:0.981\n",
            "Epochs:16, Train loss:1.47, Train accu: 0.992,Test accu:0.980\n",
            "Epochs:17, Train loss:1.47, Train accu: 0.992,Test accu:0.979\n",
            "Epochs:18, Train loss:1.47, Train accu: 0.992,Test accu:0.980\n",
            "Epochs:19, Train loss:1.47, Train accu: 0.993,Test accu:0.979\n",
            "Epochs:20, Train loss:1.47, Train accu: 0.993,Test accu:0.979\n",
            "Epochs:21, Train loss:1.47, Train accu: 0.994,Test accu:0.981\n",
            "Epochs:22, Train loss:1.47, Train accu: 0.993,Test accu:0.981\n",
            "Epochs:23, Train loss:1.47, Train accu: 0.993,Test accu:0.980\n",
            "Epochs:24, Train loss:1.47, Train accu: 0.994,Test accu:0.982\n",
            "Epochs:25, Train loss:1.47, Train accu: 0.994,Test accu:0.982\n",
            "Epochs:26, Train loss:1.47, Train accu: 0.994,Test accu:0.982\n",
            "Epochs:27, Train loss:1.47, Train accu: 0.995,Test accu:0.981\n",
            "Epochs:28, Train loss:1.47, Train accu: 0.994,Test accu:0.980\n",
            "Epochs:29, Train loss:1.47, Train accu: 0.995,Test accu:0.981\n",
            "Epochs:30, Train loss:1.47, Train accu: 0.995,Test accu:0.981\n",
            "Epochs:31, Train loss:1.47, Train accu: 0.995,Test accu:0.982\n",
            "Epochs:32, Train loss:1.47, Train accu: 0.995,Test accu:0.980\n",
            "Epochs:33, Train loss:1.47, Train accu: 0.995,Test accu:0.982\n",
            "Epochs:34, Train loss:1.47, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:35, Train loss:1.47, Train accu: 0.996,Test accu:0.984\n",
            "Epochs:36, Train loss:1.47, Train accu: 0.994,Test accu:0.981\n",
            "Epochs:37, Train loss:1.47, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:38, Train loss:1.47, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:39, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:40, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:41, Train loss:1.47, Train accu: 0.995,Test accu:0.982\n",
            "Epochs:42, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
            "Epochs:43, Train loss:1.47, Train accu: 0.995,Test accu:0.983\n",
            "Epochs:44, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:45, Train loss:1.46, Train accu: 0.995,Test accu:0.982\n",
            "Epochs:46, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:47, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:48, Train loss:1.46, Train accu: 0.996,Test accu:0.984\n",
            "Epochs:49, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:50, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:51, Train loss:1.47, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:52, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:53, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:54, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:55, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:56, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:57, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:58, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:59, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:60, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:61, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:62, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:63, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:64, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:65, Train loss:1.46, Train accu: 0.995,Test accu:0.982\n",
            "Epochs:66, Train loss:1.46, Train accu: 0.997,Test accu:0.981\n",
            "Epochs:67, Train loss:1.46, Train accu: 0.997,Test accu:0.981\n",
            "Epochs:68, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:69, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:70, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
            "Epochs:71, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:72, Train loss:1.46, Train accu: 0.997,Test accu:0.983\n",
            "Epochs:73, Train loss:1.47, Train accu: 0.995,Test accu:0.982\n",
            "Epochs:74, Train loss:1.46, Train accu: 0.997,Test accu:0.983\n",
            "Epochs:75, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
            "Epochs:76, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
            "Epochs:77, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:78, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
            "Epochs:79, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:80, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:81, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:82, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:83, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:84, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:85, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:86, Train loss:1.46, Train accu: 0.995,Test accu:0.979\n",
            "Epochs:87, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:88, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:89, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:90, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:91, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:92, Train loss:1.46, Train accu: 0.997,Test accu:0.981\n",
            "Epochs:93, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:94, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:95, Train loss:1.46, Train accu: 0.997,Test accu:0.980\n",
            "Epochs:96, Train loss:1.46, Train accu: 0.994,Test accu:0.980\n",
            "Epochs:97, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:98, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:99, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:100, Train loss:1.46, Train accu: 0.997,Test accu:0.983\n",
            "Epochs:101, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:102, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:103, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:104, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:105, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:106, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:107, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:108, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:109, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:110, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
            "Epochs:111, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:112, Train loss:1.46, Train accu: 0.995,Test accu:0.980\n",
            "Epochs:113, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
            "Epochs:114, Train loss:1.46, Train accu: 0.995,Test accu:0.980\n",
            "Epochs:115, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
            "Epochs:116, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
            "Epochs:117, Train loss:1.46, Train accu: 0.994,Test accu:0.978\n",
            "Epochs:118, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:119, Train loss:1.46, Train accu: 0.995,Test accu:0.978\n",
            "Epochs:120, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
            "Epochs:121, Train loss:1.46, Train accu: 0.996,Test accu:0.978\n",
            "Epochs:122, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
            "Epochs:123, Train loss:1.46, Train accu: 0.996,Test accu:0.979\n",
            "Epochs:124, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n"
          ]
        }
      ]
    }
  ]
}